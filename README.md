# ML-with-Python-and-R
Master Machine Learning with Python and R Languages (yet to be converted to ipynb)

# Regression

***Linear Regression***
1) Pros

Works on any size of dataset, gives
informations about relevance of features
2) Cons

The Linear Regression Assumptions

***Polynomial Regression***
1) Pros

Works on any size of dataset, works very
well on non linear problems
2) Cons

Need to choose the right polynomial degree
for a good bias/variance tradeoff

***Support Vector Regression***
1) Pros

Easily adaptable, works very well on non
linear problems, not biased by outliers
2) Cons

Compulsory to apply feature scaling, not
well known, more difficult to understand

***Decision Tree Regression***
1) Pros

Interpretability, no need for feature scaling,
works on both linear / nonlinear problems
2) Cons

Poor results on too small datasets,
overfitting can easily occur

***Random Forest Regression***
1) Pros

Powerful and accurate, good performance
on many problems, including non linear
2) Cons

No interpretability, overfitting can easily
occur, need to choose the number of trees

#Classification

***Logistic Regression***
1) Pros

Probabilistic approach, gives informations
about statistical significance of features 
2) Cons

The Logistic Regression Assumptions

***K-Nearest Neighbours***
1) Pros

Simple to understand, fast and efficient 
2) Cons

Need to choose the number of neighbours k

***Support Vector Machines***
1) Pros

Performant, not biased by outliers,
not sensitive to overfitting
2) Cons

Not appropriate for non linear problems, not
the best choice for large number of features

***Kernal SVM***
1) Pros

High performance on nonlinear problems, not
biased by outliers, not sensitive to overfitting
2) Cons

Not the best choice for large number of
features, more complex

***Naive Bayes***
1) Pros

Efficient, not biased by outliers, works on
nonlinear problems, probabilistic approach
2) Cons

Based on the assumption that features
have same statistical relevance

***Decision Tree Classifier***
1) Pros

Interpretability, no need for feature scaling,
works on both linear / nonlinear problems
2) Cons

Poor results on too small datasets,
overfitting can easily occur

***Random Forest Classifier***
1) Pros

Powerful and accurate, good performance on
many problems, including non linear
2) Cons

No interpretability, overfitting can easily
occur, need to choose the number of trees

# Clustering

***K-Means Clustering***
1) Pros

Simple to understand, easily adaptable,
works well on small or large datasets,
fast, efficient and performant
2) Cons

Need to choose the number of clusters

***Hierarchical Clustering***
1) Pros

The optimal number of clusters can be
obtained by the model itself, practical
visualisation with the dendrogram
2) Cons

Not appropriate for large datasets
